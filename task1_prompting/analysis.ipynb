{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df3420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and API configured.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Replace with your actual Gemini API Key from Google AI Studio\n",
    "GOOGLE_API_KEY = \"AIzaSyAE-Stt-y-c3up-GAg5YE0F2og2x-eYZks\" \n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-flash-lite-latest')\n",
    "\n",
    "print(\"Libraries imported and API configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086733f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Total rows: 10000\n",
      "Columns found: ['business_id', 'date', 'review_id', 'stars', 'text', 'type', 'user_id', 'cool', 'useful', 'funny']\n",
      "\n",
      "Sample Data:\n",
      "   stars                                               text\n",
      "0      4  We got here around midnight last Friday... the...\n",
      "1      5  Brought a friend from Louisiana here.  She say...\n",
      "2      3  Every friday, my dad and I eat here. We order ...\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the dataset\n",
    "try:\n",
    "    # Attempt to read the CSV. \n",
    "    # Note: If your file is named something else, change 'yelp.csv' below.\n",
    "    df = pd.read_csv('yelp.csv')\n",
    "    print(f\"Dataset loaded. Total rows: {len(df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå ERROR: 'yelp.csv' not found. Please download the dataset and place it in this folder.\")\n",
    "    df = pd.DataFrame() # Create empty to prevent crash in next steps\n",
    "\n",
    "# 2. Sample 200 rows (Requirement: ~200 rows)\n",
    "if not df.empty:\n",
    "    # We use .copy() to ensure we have a clean standalone dataframe\n",
    "    df_sampled = df.sample(n=50, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # 3. Verify column names (Yelp datasets usually have 'stars' and 'text')\n",
    "    print(\"Columns found:\", df_sampled.columns.tolist())\n",
    "    \n",
    "    # Show first 3 rows to check data\n",
    "    print(\"\\nSample Data:\")\n",
    "    print(df_sampled[['stars', 'text']].head(3))\n",
    "else:\n",
    "    print(\"Cannot proceed without data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6bbd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function defined successfully.\n"
     ]
    }
   ],
   "source": [
    "def extract_json(text):\n",
    "    \"\"\"\n",
    "    Finds a JSON object inside a string using Regex.\n",
    "    Solves the issue where LLM adds markdown like ```json ... ```\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Regex to find text between { and } across multiple lines\n",
    "        match = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
    "        if match:\n",
    "            json_str = match.group(0)\n",
    "            return json.loads(json_str)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def get_prediction(review_text, strategy):\n",
    "    \"\"\"\n",
    "    Sends the review to Gemini using one of 3 strategies.\n",
    "    Returns: JSON object with 'predicted_stars' and 'explanation'\n",
    "    \"\"\"\n",
    "    \n",
    "    base_instruction = \"\"\"\n",
    "    Analyze the sentiment of this Yelp review.\n",
    "    Determine the rating (1 to 5 stars).\n",
    "    Output strictly VALID JSON in this format:\n",
    "    {\"predicted_stars\": <int>, \"explanation\": \"<short string>\"}\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- STRATEGY 1: ZERO-SHOT ---\n",
    "    if strategy == \"zero_shot\":\n",
    "        prompt = f\"{base_instruction}\\n\\nReview: {review_text}\"\n",
    "\n",
    "    # --- STRATEGY 2: FEW-SHOT (Providing examples) ---\n",
    "    elif strategy == \"few_shot\":\n",
    "        examples = \"\"\"\n",
    "        Examples:\n",
    "        Review: \"The service was slow and food was cold.\" -> {\"predicted_stars\": 1, \"explanation\": \"Negative sentiment regarding service and food.\"}\n",
    "        Review: \"Absolutely delicious! Best pizza in town.\" -> {\"predicted_stars\": 5, \"explanation\": \"Highly positive review.\"}\n",
    "        \"\"\"\n",
    "        prompt = f\"{base_instruction}\\n{examples}\\n\\nReview: {review_text}\"\n",
    "\n",
    "    # --- STRATEGY 3: CHAIN-OF-THOUGHT (Step-by-step reasoning) ---\n",
    "    elif strategy == \"chain_of_thought\":\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert critic. Follow these steps:\n",
    "        1. Identify the key adjectives in the text.\n",
    "        2. Determine if the tone is angry, neutral, or happy.\n",
    "        3. Assign a score from 1-5.\n",
    "        \n",
    "        {base_instruction}\n",
    "        \n",
    "        Review: {review_text}\n",
    "        \"\"\"\n",
    "    \n",
    "    # Call the API\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        result = extract_json(response.text)\n",
    "        \n",
    "        # Validation: Check if we got a star rating\n",
    "        if result and 'predicted_stars' in result:\n",
    "            return result\n",
    "        else:\n",
    "            return {\"predicted_stars\": 0, \"explanation\": \"Error: JSON parsing failed\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\"predicted_stars\": 0, \"explanation\": f\"API Error: {str(e)}\"}\n",
    "\n",
    "print(\"Function defined successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd489f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing of 50 rows...\n",
      "Processed 5 rows...\n",
      "Processed 10 rows...\n",
      "Processed 15 rows...\n",
      "Processed 20 rows...\n",
      "Processed 25 rows...\n",
      "Processed 30 rows...\n",
      "Processed 35 rows...\n",
      "Processed 40 rows...\n",
      "Processed 45 rows...\n",
      "Processed 50 rows...\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# Ensure df_sampled is actually defined (use the 50 rows version if possible)\n",
    "print(f\"Starting processing of {len(df_sampled)} rows...\") \n",
    "\n",
    "if not df_sampled.empty:\n",
    "    for index, row in df_sampled.iterrows():\n",
    "        actual_stars = row['stars']\n",
    "        review_text = row['text']\n",
    "        \n",
    "        # Test all 3 strategies for this single review\n",
    "        for strategy in [\"zero_shot\", \"few_shot\", \"chain_of_thought\"]:\n",
    "            \n",
    "            # Get AI prediction\n",
    "            ai_output = get_prediction(review_text, strategy)\n",
    "            \n",
    "            # Store result\n",
    "            results.append({\n",
    "                \"review_id\": index,\n",
    "                \"strategy\": strategy,\n",
    "                \"actual_stars\": actual_stars,\n",
    "                \"predicted_stars\": ai_output['predicted_stars'],\n",
    "                \"explanation\": ai_output['explanation'],\n",
    "                \"is_valid\": 1 if (1 <= ai_output['predicted_stars'] <= 5) else 0\n",
    "            })\n",
    "            \n",
    "            # === CRITICAL CHANGE ===\n",
    "            # Sleep 4 seconds between EACH call. \n",
    "            # 3 calls per row * 4s = 12s per row.\n",
    "            # 60s / 12s = 5 rows per minute (15 requests/min).\n",
    "            # This is safe for the Free Tier.\n",
    "            time.sleep(4) \n",
    "            \n",
    "        # Progress indicator\n",
    "        if (index + 1) % 5 == 0:\n",
    "            print(f\"Processed {index + 1} rows...\")\n",
    "\n",
    "    print(\"Processing complete!\")\n",
    "    \n",
    "    # Convert list to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "else:\n",
    "    print(\"No data to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3bf6571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL RESULTS ===\n",
      "                  Accuracy  JSON_Validity\n",
      "strategy                                 \n",
      "chain_of_thought      0.10           0.12\n",
      "few_shot              0.12           0.16\n",
      "zero_shot             0.10           0.14\n",
      "\n",
      "=== Mismatch Examples (Zero-Shot) ===\n",
      "Actual: 5 | Predicted: 0\n",
      "Reasoning: API Error: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash-lite\n",
      "Please retry in 34.343814345s. [links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-flash-lite\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 10\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "]\n",
      "\n",
      "Actual: 4 | Predicted: 5\n",
      "Reasoning: The review is overwhelmingly positive, praising the location, price, free parking, clean and large rooms, and decent free breakfast, despite minor noise from the bathroom. The reviewer explicitly states it's a 'great choice' and they'd 'stay again'.\n",
      "\n",
      "Actual: 4 | Predicted: 5\n",
      "Reasoning: The reviewer uses highly positive language like 'Awesome' and 'awesomer' to describe both the ramen and the boba tea.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not results_df.empty:\n",
    "    # 1. Calculate Accuracy and JSON Validity\n",
    "    # We use .agg() to avoid the Pandas Future Warning\n",
    "    metrics = results_df.groupby('strategy').agg(\n",
    "        Accuracy=('predicted_stars', lambda x: accuracy_score(results_df.loc[x.index, 'actual_stars'], x)),\n",
    "        JSON_Validity=('is_valid', 'mean') # Percentage of valid JSONs\n",
    "    )\n",
    "    \n",
    "    print(\"=== FINAL RESULTS ===\")\n",
    "    print(metrics)\n",
    "    \n",
    "    # 2. Show a few mismatch examples (Good for the report)\n",
    "    print(\"\\n=== Mismatch Examples (Zero-Shot) ===\")\n",
    "    mismatches = results_df[\n",
    "        (results_df['strategy'] == 'zero_shot') & \n",
    "        (results_df['actual_stars'] != results_df['predicted_stars'])\n",
    "    ].head(3)\n",
    "    \n",
    "    for i, row in mismatches.iterrows():\n",
    "        print(f\"Actual: {row['actual_stars']} | Predicted: {row['predicted_stars']}\")\n",
    "        print(f\"Reasoning: {row['explanation']}\\n\")\n",
    "\n",
    "else:\n",
    "    print(\"No results to show.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
